{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d130f8fd",
   "metadata": {},
   "source": [
    "# Setup & Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100075fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HYPERTHYROID DETECTION - MODEL TRAINING & EVALUATION\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Train: (6342, 27), Val: (1359, 27), Test: (1359, 27)\n",
      "\n",
      "üìä Features: 26, Classes: 3\n",
      "‚úÖ Scaling complete!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# HYPERTHYROID DETECTION - MODEL TRAINING & EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                            accuracy_score, precision_score, recall_score, \n",
    "                            f1_score, roc_auc_score, matthews_corrcoef)\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier, AdaBoostClassifier\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HYPERTHYROID DETECTION - MODEL TRAINING & EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('../data/train_set.csv')\n",
    "val_df = pd.read_csv('../data/val_set.csv')\n",
    "test_df = pd.read_csv('../data/test_set.csv')\n",
    "\n",
    "print(f\"\\n‚úÖ Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}\")\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_df.drop('hyperlabel', axis=1)\n",
    "y_train = train_df['hyperlabel']\n",
    "X_val = val_df.drop('hyperlabel', axis=1)\n",
    "y_val = val_df['hyperlabel']\n",
    "X_test = test_df.drop('hyperlabel', axis=1)\n",
    "y_test = test_df['hyperlabel']\n",
    "\n",
    "# Remove non-numeric columns\n",
    "object_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "if len(object_cols) > 0:\n",
    "    print(f\"\\nüîß Removing {len(object_cols)} non-numeric columns: {object_cols}\")\n",
    "    X_train = X_train.drop(columns=object_cols)\n",
    "    X_val = X_val.drop(columns=object_cols)\n",
    "    X_test = X_test.drop(columns=object_cols)\n",
    "\n",
    "print(f\"\\nüìä Features: {X_train.shape[1]}, Classes: {y_train.nunique()}\")\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úÖ Scaling complete!\\n\" + \"=\"*70)\n",
    "\n",
    "# Storage for all models\n",
    "models = {}\n",
    "predictions = {}\n",
    "training_times = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8cddd0",
   "metadata": {},
   "source": [
    "# Model 1: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d79f4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üå≤ MODEL 1: RANDOM FOREST\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Training Time: 0.14s\n",
      "üìä Validation Accuracy: 1.0000 (100.00%)\n",
      "üìä Validation F1-Score: 1.0000\n",
      "\n",
      "üìà Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00      1074\n",
      " Subclinical       1.00      1.00      1.00        75\n",
      "       Overt       1.00      1.00      1.00       210\n",
      "\n",
      "    accuracy                           1.00      1359\n",
      "   macro avg       1.00      1.00      1.00      1359\n",
      "weighted avg       1.00      1.00      1.00      1359\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODEL 1: RANDOM FOREST\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üå≤ MODEL 1: RANDOM FOREST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "training_times['Random Forest'] = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "y_val_proba_rf = rf_model.predict_proba(X_val)\n",
    "\n",
    "# Quick evaluation\n",
    "val_acc = accuracy_score(y_val, y_val_pred_rf)\n",
    "val_f1 = f1_score(y_val, y_val_pred_rf, average='macro')\n",
    "\n",
    "print(f\"\\n‚úÖ Training Time: {training_times['Random Forest']:.2f}s\")\n",
    "print(f\"üìä Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"üìä Validation F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_rf, \n",
    "                          target_names=['Normal', 'Subclinical', 'Overt']))\n",
    "\n",
    "# Store\n",
    "models['Random Forest'] = rf_model\n",
    "predictions['Random Forest'] = {\n",
    "    'val': y_val_pred_rf,\n",
    "    'val_proba': y_val_proba_rf,\n",
    "    'test': rf_model.predict(X_test),\n",
    "    'test_proba': rf_model.predict_proba(X_test)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78056149",
   "metadata": {},
   "source": [
    "# Model 2: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25a838e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ MODEL 2: GRADIENT BOOSTING\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Training Time: 1.02s\n",
      "üìä Validation Accuracy: 1.0000 (100.00%)\n",
      "üìä Validation F1-Score: 1.0000\n",
      "\n",
      "üìà Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00      1074\n",
      " Subclinical       1.00      1.00      1.00        75\n",
      "       Overt       1.00      1.00      1.00       210\n",
      "\n",
      "    accuracy                           1.00      1359\n",
      "   macro avg       1.00      1.00      1.00      1359\n",
      "weighted avg       1.00      1.00      1.00      1359\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODEL 2: GRADIENT BOOSTING\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ MODEL 2: GRADIENT BOOSTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "training_times['Gradient Boosting'] = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_val_pred_gb = gb_model.predict(X_val)\n",
    "y_val_proba_gb = gb_model.predict_proba(X_val)\n",
    "\n",
    "# Quick evaluation\n",
    "val_acc = accuracy_score(y_val, y_val_pred_gb)\n",
    "val_f1 = f1_score(y_val, y_val_pred_gb, average='macro')\n",
    "\n",
    "print(f\"\\n‚úÖ Training Time: {training_times['Gradient Boosting']:.2f}s\")\n",
    "print(f\"üìä Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"üìä Validation F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_gb, \n",
    "                          target_names=['Normal', 'Subclinical', 'Overt']))\n",
    "\n",
    "# Store\n",
    "models['Gradient Boosting'] = gb_model\n",
    "predictions['Gradient Boosting'] = {\n",
    "    'val': y_val_pred_gb,\n",
    "    'val_proba': y_val_proba_gb,\n",
    "    'test': gb_model.predict(X_test),\n",
    "    'test_proba': gb_model.predict_proba(X_test)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dccc25b",
   "metadata": {},
   "source": [
    "# Model 3: Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebaa49bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìà MODEL 3: LOGISTIC REGRESSION\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Training Time: 2.21s\n",
      "üìä Validation Accuracy: 0.8263 (82.63%)\n",
      "üìä Validation F1-Score: 0.7177\n",
      "\n",
      "üìà Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      0.80      0.89      1074\n",
      " Subclinical       0.32      0.96      0.48        75\n",
      "       Overt       0.70      0.89      0.78       210\n",
      "\n",
      "    accuracy                           0.83      1359\n",
      "   macro avg       0.67      0.88      0.72      1359\n",
      "weighted avg       0.91      0.83      0.85      1359\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODEL 3: LOGISTIC REGRESSION\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìà MODEL 3: LOGISTIC REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "training_times['Logistic Regression'] = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_val_pred_lr = lr_model.predict(X_val_scaled)\n",
    "y_val_proba_lr = lr_model.predict_proba(X_val_scaled)\n",
    "\n",
    "# Quick evaluation\n",
    "val_acc = accuracy_score(y_val, y_val_pred_lr)\n",
    "val_f1 = f1_score(y_val, y_val_pred_lr, average='macro')\n",
    "\n",
    "print(f\"\\n‚úÖ Training Time: {training_times['Logistic Regression']:.2f}s\")\n",
    "print(f\"üìä Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"üìä Validation F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_lr, \n",
    "                          target_names=['Normal', 'Subclinical', 'Overt']))\n",
    "\n",
    "# Store\n",
    "models['Logistic Regression'] = lr_model\n",
    "predictions['Logistic Regression'] = {\n",
    "    'val': y_val_pred_lr,\n",
    "    'val_proba': y_val_proba_lr,\n",
    "    'test': lr_model.predict(X_test_scaled),\n",
    "    'test_proba': lr_model.predict_proba(X_test_scaled)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca6d29c",
   "metadata": {},
   "source": [
    "# Model 4: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ed8b75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚ö° MODEL 4: SVM (Support Vector Machine)\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Training Time: 6.27s\n",
      "üìä Validation Accuracy: 0.7682 (76.82%)\n",
      "üìä Validation F1-Score: 0.6520\n",
      "\n",
      "üìà Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.96      0.75      0.84      1074\n",
      " Subclinical       0.29      0.84      0.43        75\n",
      "       Overt       0.59      0.83      0.69       210\n",
      "\n",
      "    accuracy                           0.77      1359\n",
      "   macro avg       0.61      0.81      0.65      1359\n",
      "weighted avg       0.87      0.77      0.80      1359\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODEL 4: SVM (SUPPORT VECTOR MACHINE) - NEW!\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚ö° MODEL 4: SVM (Support Vector Machine)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_model = SVC(\n",
    "    kernel='rbf',              # Radial Basis Function kernel\n",
    "    C=10,                      # Regularization parameter\n",
    "    gamma='scale',             # Kernel coefficient\n",
    "    class_weight='balanced',   # Handle imbalanced classes\n",
    "    probability=True,          # Enable probability estimates\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "training_times['SVM'] = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_val_pred_svm = svm_model.predict(X_val_scaled)\n",
    "y_val_proba_svm = svm_model.predict_proba(X_val_scaled)\n",
    "\n",
    "# Quick evaluation\n",
    "val_acc = accuracy_score(y_val, y_val_pred_svm)\n",
    "val_f1 = f1_score(y_val, y_val_pred_svm, average='macro')\n",
    "\n",
    "print(f\"\\n‚úÖ Training Time: {training_times['SVM']:.2f}s\")\n",
    "print(f\"üìä Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"üìä Validation F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_svm, \n",
    "                          target_names=['Normal', 'Subclinical', 'Overt']))\n",
    "\n",
    "# Store\n",
    "models['SVM'] = svm_model\n",
    "predictions['SVM'] = {\n",
    "    'val': y_val_pred_svm,\n",
    "    'val_proba': y_val_proba_svm,\n",
    "    'test': svm_model.predict(X_test_scaled),\n",
    "    'test_proba': svm_model.predict_proba(X_test_scaled)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96e20f",
   "metadata": {},
   "source": [
    "# Model 5: MLP (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cc32226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üß† MODEL 5: MLP (Neural Network)\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Training Time: 2.52s\n",
      "   Iterations: 33\n",
      "üìä Validation Accuracy: 0.9455 (94.55%)\n",
      "üìä Validation F1-Score: 0.8727\n",
      "\n",
      "üìà Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.96      0.97      0.97      1074\n",
      " Subclinical       0.76      0.75      0.75        75\n",
      "       Overt       0.93      0.87      0.90       210\n",
      "\n",
      "    accuracy                           0.95      1359\n",
      "   macro avg       0.88      0.86      0.87      1359\n",
      "weighted avg       0.95      0.95      0.95      1359\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODEL 5: MLP (MULTI-LAYER PERCEPTRON)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üß† MODEL 5: MLP (Neural Network)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "mlp_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 32),  # 3 hidden layers\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.001,\n",
    "    batch_size=32,\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=200,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "training_times['MLP'] = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_val_pred_mlp = mlp_model.predict(X_val_scaled)\n",
    "y_val_proba_mlp = mlp_model.predict_proba(X_val_scaled)\n",
    "\n",
    "# Quick evaluation\n",
    "val_acc = accuracy_score(y_val, y_val_pred_mlp)\n",
    "val_f1 = f1_score(y_val, y_val_pred_mlp, average='macro')\n",
    "\n",
    "print(f\"\\n‚úÖ Training Time: {training_times['MLP']:.2f}s\")\n",
    "print(f\"   Iterations: {mlp_model.n_iter_}\")\n",
    "print(f\"üìä Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"üìä Validation F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_mlp, \n",
    "                          target_names=['Normal', 'Subclinical', 'Overt']))\n",
    "\n",
    "# Store\n",
    "models['MLP'] = mlp_model\n",
    "predictions['MLP'] = {\n",
    "    'val': y_val_pred_mlp,\n",
    "    'val_proba': y_val_proba_mlp,\n",
    "    'test': mlp_model.predict(X_test_scaled),\n",
    "    'test_proba': mlp_model.predict_proba(X_test_scaled)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c8b76",
   "metadata": {},
   "source": [
    "# Model 6: KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ad3b6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë• MODEL 6: KNN (K-Nearest Neighbors)\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Training Time: 0.00s\n",
      "üìä Validation Accuracy: 0.8263 (82.63%)\n",
      "üìä Validation F1-Score: 0.4847\n",
      "\n",
      "üìà Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.84      0.97      0.90      1074\n",
      " Subclinical       0.33      0.03      0.05        75\n",
      "       Overt       0.68      0.40      0.50       210\n",
      "\n",
      "    accuracy                           0.83      1359\n",
      "   macro avg       0.62      0.46      0.48      1359\n",
      "weighted avg       0.79      0.83      0.79      1359\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODEL 6: KNN (K-NEAREST NEIGHBORS) - NEW!\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üë• MODEL 6: KNN (K-Nearest Neighbors)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "knn_model = KNeighborsClassifier(\n",
    "    n_neighbors=11,            # Number of neighbors\n",
    "    weights='distance',        # Weight by inverse distance\n",
    "    metric='minkowski',        # Distance metric\n",
    "    p=2,                       # p=2 means Euclidean distance\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "training_times['KNN'] = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_val_pred_knn = knn_model.predict(X_val_scaled)\n",
    "y_val_proba_knn = knn_model.predict_proba(X_val_scaled)\n",
    "\n",
    "# Quick evaluation\n",
    "val_acc = accuracy_score(y_val, y_val_pred_knn)\n",
    "val_f1 = f1_score(y_val, y_val_pred_knn, average='macro')\n",
    "\n",
    "print(f\"\\n‚úÖ Training Time: {training_times['KNN']:.2f}s\")\n",
    "print(f\"üìä Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"üìä Validation F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_knn, \n",
    "                          target_names=['Normal', 'Subclinical', 'Overt']))\n",
    "\n",
    "# Store\n",
    "models['KNN'] = knn_model\n",
    "predictions['KNN'] = {\n",
    "    'val': y_val_pred_knn,\n",
    "    'val_proba': y_val_proba_knn,\n",
    "    'test': knn_model.predict(X_test_scaled),\n",
    "    'test_proba': knn_model.predict_proba(X_test_scaled)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0d3ba",
   "metadata": {},
   "source": [
    "# Model 7: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f38d01b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üå≥ MODEL 7: DECISION TREE\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Training Time: 0.00s\n",
      "üìä Validation Accuracy: 1.0000 (100.00%)\n",
      "üìä Validation F1-Score: 1.0000\n",
      "üå≥ Tree Depth: 4\n",
      "üçÉ Number of Leaves: 6\n",
      "\n",
      "üìà Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00      1074\n",
      " Subclinical       1.00      1.00      1.00        75\n",
      "       Overt       1.00      1.00      1.00       210\n",
      "\n",
      "    accuracy                           1.00      1359\n",
      "   macro avg       1.00      1.00      1.00      1359\n",
      "weighted avg       1.00      1.00      1.00      1359\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODEL 7: DECISION TREE - NEW!\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üå≥ MODEL 7: DECISION TREE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=10,              # Maximum depth of tree\n",
    "    min_samples_split=20,      # Min samples to split node\n",
    "    min_samples_leaf=10,       # Min samples in leaf\n",
    "    class_weight='balanced',   # Handle imbalanced classes\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "training_times['Decision Tree'] = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_val_pred_dt = dt_model.predict(X_val)\n",
    "y_val_proba_dt = dt_model.predict_proba(X_val)\n",
    "\n",
    "# Quick evaluation\n",
    "val_acc = accuracy_score(y_val, y_val_pred_dt)\n",
    "val_f1 = f1_score(y_val, y_val_pred_dt, average='macro')\n",
    "\n",
    "print(f\"\\n‚úÖ Training Time: {training_times['Decision Tree']:.2f}s\")\n",
    "print(f\"üìä Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"üìä Validation F1-Score: {val_f1:.4f}\")\n",
    "print(f\"üå≥ Tree Depth: {dt_model.get_depth()}\")\n",
    "print(f\"üçÉ Number of Leaves: {dt_model.get_n_leaves()}\")\n",
    "\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_dt, \n",
    "                          target_names=['Normal', 'Subclinical', 'Overt']))\n",
    "\n",
    "# Store\n",
    "models['Decision Tree'] = dt_model\n",
    "predictions['Decision Tree'] = {\n",
    "    'val': y_val_pred_dt,\n",
    "    'val_proba': y_val_proba_dt,\n",
    "    'test': dt_model.predict(X_test),\n",
    "    'test_proba': dt_model.predict_proba(X_test)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c445567b",
   "metadata": {},
   "source": [
    "# Model 8: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ed946df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä MODEL 8: NAIVE BAYES (Gaussian)\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Training Time: 0.00s\n",
      "üìä Validation Accuracy: 0.8536 (85.36%)\n",
      "üìä Validation F1-Score: 0.6568\n",
      "\n",
      "üìà Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      0.93      0.96      1074\n",
      " Subclinical       0.27      0.89      0.41        75\n",
      "       Overt       0.86      0.45      0.59       210\n",
      "\n",
      "    accuracy                           0.85      1359\n",
      "   macro avg       0.71      0.76      0.66      1359\n",
      "weighted avg       0.94      0.85      0.87      1359\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODEL 8: NAIVE BAYES (GAUSSIAN) - NEW!\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä MODEL 8: NAIVE BAYES (Gaussian)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "training_times['Naive Bayes'] = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_val_pred_nb = nb_model.predict(X_val_scaled)\n",
    "y_val_proba_nb = nb_model.predict_proba(X_val_scaled)\n",
    "\n",
    "# Quick evaluation\n",
    "val_acc = accuracy_score(y_val, y_val_pred_nb)\n",
    "val_f1 = f1_score(y_val, y_val_pred_nb, average='macro')\n",
    "\n",
    "print(f\"\\n‚úÖ Training Time: {training_times['Naive Bayes']:.2f}s\")\n",
    "print(f\"üìä Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"üìä Validation F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_nb, \n",
    "                          target_names=['Normal', 'Subclinical', 'Overt']))\n",
    "\n",
    "# Store\n",
    "models['Naive Bayes'] = nb_model\n",
    "predictions['Naive Bayes'] = {\n",
    "    'val': y_val_pred_nb,\n",
    "    'val_proba': y_val_proba_nb,\n",
    "    'test': nb_model.predict(X_test_scaled),\n",
    "    'test_proba': nb_model.predict_proba(X_test_scaled)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ce028",
   "metadata": {},
   "source": [
    "# Model 9: Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccd2cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üå≤üå≤ MODEL 9: EXTRA TREES\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Training Time: 0.11s\n",
      "üìä Validation Accuracy: 0.6652 (66.52%)\n",
      "üìä Validation F1-Score: 0.5619\n",
      "\n",
      "üìà Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.97      0.63      0.76      1074\n",
      " Subclinical       0.17      0.79      0.28        75\n",
      "       Overt       0.54      0.80      0.64       210\n",
      "\n",
      "    accuracy                           0.67      1359\n",
      "   macro avg       0.56      0.74      0.56      1359\n",
      "weighted avg       0.86      0.67      0.72      1359\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODEL 9: EXTRA TREES (Extremely Randomized Trees) - NEW!\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üå≤üå≤ MODEL 9: EXTRA TREES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "et_model = ExtraTreesClassifier(\n",
    "    n_estimators=100,          # Number of trees\n",
    "    max_depth=15,              # Maximum depth\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "et_model.fit(X_train, y_train)\n",
    "training_times['Extra Trees'] = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_val_pred_et = et_model.predict(X_val)\n",
    "y_val_proba_et = et_model.predict_proba(X_val)\n",
    "\n",
    "# Quick evaluation\n",
    "val_acc = accuracy_score(y_val, y_val_pred_et)\n",
    "val_f1 = f1_score(y_val, y_val_pred_et, average='macro')\n",
    "\n",
    "print(f\"\\n‚úÖ Training Time: {training_times['Extra Trees']:.2f}s\")\n",
    "print(f\"üìä Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"üìä Validation F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_et, \n",
    "                          target_names=['Normal', 'Subclinical', 'Overt']))\n",
    "\n",
    "# Store\n",
    "models['Extra Trees'] = et_model\n",
    "predictions['Extra Trees'] = {\n",
    "    'val': y_val_pred_et,\n",
    "    'val_proba': y_val_proba_et,\n",
    "    'test': et_model.predict(X_test),\n",
    "    'test_proba': et_model.predict_proba(X_test)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fc791c",
   "metadata": {},
   "source": [
    "# Model 10: AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d049dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéØ MODEL 10: ADABOOST\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Training Time: 0.32s\n",
      "üìä Validation Accuracy: 1.0000 (100.00%)\n",
      "üìä Validation F1-Score: 1.0000\n",
      "\n",
      "üìà Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00      1074\n",
      " Subclinical       1.00      1.00      1.00        75\n",
      "       Overt       1.00      1.00      1.00       210\n",
      "\n",
      "    accuracy                           1.00      1359\n",
      "   macro avg       1.00      1.00      1.00      1359\n",
      "weighted avg       1.00      1.00      1.00      1359\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODEL 10: ADABOOST (Adaptive Boosting) - NEW!\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ MODEL 10: ADABOOST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "ada_model = AdaBoostClassifier(\n",
    "    n_estimators=100,          # Number of boosting stages\n",
    "    learning_rate=0.5,         # Learning rate\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada_model.fit(X_train, y_train)\n",
    "training_times['AdaBoost'] = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_val_pred_ada = ada_model.predict(X_val)\n",
    "y_val_proba_ada = ada_model.predict_proba(X_val)\n",
    "\n",
    "# Quick evaluation\n",
    "val_acc = accuracy_score(y_val, y_val_pred_ada)\n",
    "val_f1 = f1_score(y_val, y_val_pred_ada, average='macro')\n",
    "\n",
    "print(f\"\\n‚úÖ Training Time: {training_times['AdaBoost']:.2f}s\")\n",
    "print(f\"üìä Validation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "print(f\"üìä Validation F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_ada, \n",
    "                          target_names=['Normal', 'Subclinical', 'Overt']))\n",
    "\n",
    "# Store\n",
    "models['AdaBoost'] = ada_model\n",
    "predictions['AdaBoost'] = {\n",
    "    'val': y_val_pred_ada,\n",
    "    'val_proba': y_val_proba_ada,\n",
    "    'test': ada_model.predict(X_test),\n",
    "    'test_proba': ada_model.predict_proba(X_test)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a675a204",
   "metadata": {},
   "source": [
    "# COMPREHENSIVE EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ca68c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                    COMPREHENSIVE MODEL EVALUATION\n",
      "================================================================================\n",
      "\n",
      "üìä Calculating comprehensive metrics for all models...\n",
      "‚öôÔ∏è Evaluating Random Forest...\n",
      "‚öôÔ∏è Evaluating Gradient Boosting...\n",
      "‚öôÔ∏è Evaluating Logistic Regression...\n",
      "‚öôÔ∏è Evaluating SVM...\n",
      "‚öôÔ∏è Evaluating MLP...\n",
      "‚öôÔ∏è Evaluating KNN...\n",
      "‚öôÔ∏è Evaluating Decision Tree...\n",
      "‚öôÔ∏è Evaluating Naive Bayes...\n",
      "‚öôÔ∏è Evaluating Extra Trees...\n",
      "‚öôÔ∏è Evaluating AdaBoost...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6. COMPREHENSIVE MODEL EVALUATION\n",
    "# ============================================================\n",
    "# Professional evaluation with all metrics: AUROC, F1, MCC, \n",
    "# Precision, Recall, Confusion Matrices, and Test Set Validation\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \" * 20 + \"COMPREHENSIVE MODEL EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# PART 1: Calculate All Metrics for Each Model\n",
    "# ============================================================\n",
    "print(\"\\nüìä Calculating comprehensive metrics for all models...\")\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for model_name in models.keys():\n",
    "    print(f\"‚öôÔ∏è Evaluating {model_name}...\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_val_pred = predictions[model_name]['val']\n",
    "    y_val_proba = predictions[model_name]['val_proba']\n",
    "    y_test_pred = predictions[model_name]['test']\n",
    "    y_test_proba = predictions[model_name]['test_proba']\n",
    "    \n",
    "    # ========================================\n",
    "    # VALIDATION SET METRICS\n",
    "    # ========================================\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_precision = precision_score(y_val, y_val_pred, average='macro', zero_division=0)\n",
    "    val_recall = recall_score(y_val, y_val_pred, average='macro', zero_division=0)\n",
    "    val_f1 = f1_score(y_val, y_val_pred, average='macro', zero_division=0)\n",
    "    val_mcc = matthews_corrcoef(y_val, y_val_pred)\n",
    "    \n",
    "    # AUROC (One-vs-Rest for multiclass)\n",
    "    try:\n",
    "        y_val_bin = label_binarize(y_val, classes=[0, 1, 2])\n",
    "        val_auroc = roc_auc_score(y_val_bin, y_val_proba, average='macro', multi_class='ovr')\n",
    "    except:\n",
    "        val_auroc = np.nan\n",
    "    \n",
    "    # ========================================\n",
    "    # TEST SET METRICS\n",
    "    # ========================================\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "    test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
    "    \n",
    "    # AUROC for test set\n",
    "    try:\n",
    "        y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
    "        test_auroc = roc_auc_score(y_test_bin, y_test_proba, average='macro', multi_class='ovr')\n",
    "    except:\n",
    "        test_auroc = np.nan\n",
    "    \n",
    "    # Store results\n",
    "    evaluation_results.append({\n",
    "        'Model': model_name,\n",
    "        'Val_Accuracy': val_accuracy,\n",
    "        'Val_Precision': val_precision,\n",
    "        'Val_Recall': val_recall,\n",
    "        'Val_F1': val_f1,\n",
    "        'Val_AUROC': val_auroc,\n",
    "        'Val_MCC': val_mcc,\n",
    "        'Test_Accuracy': test_accuracy,\n",
    "        'Test_Precision': test_precision,\n",
    "        'Test_Recall': test_recall,\n",
    "        'Test_F1': test_f1,\n",
    "        'Test_AUROC': test_auroc,\n",
    "        'Test_MCC': test_mcc,\n",
    "        'Training_Time': training_times[model_name]\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fe7dbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VALIDATION SET RESULTS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "              Model  Accuracy  Precision  Recall  F1-Score  AUROC    MCC  Time (s)\n",
      "      Random Forest    1.0000     1.0000  1.0000    1.0000 1.0000 1.0000    0.1408\n",
      "  Gradient Boosting    1.0000     1.0000  1.0000    1.0000 1.0000 1.0000    1.0234\n",
      "Logistic Regression    0.8263     0.6718  0.8850    0.7177 0.9585 0.6603    2.2052\n",
      "                SVM    0.7682     0.6103  0.8079    0.6520 0.9322 0.5451    6.2668\n",
      "                MLP    0.9455     0.8835  0.8627    0.8727 0.9888 0.8408    2.5152\n",
      "                KNN    0.8263     0.6198  0.4641    0.4847 0.7614 0.3948    0.0010\n",
      "      Decision Tree    1.0000     1.0000  1.0000    1.0000 1.0000 1.0000    0.0047\n",
      "        Naive Bayes    0.8536     0.7103  0.7583    0.6568 0.9712 0.6524    0.0025\n",
      "        Extra Trees    0.6652     0.5574  0.7390    0.5619 0.8927 0.4485    0.1091\n",
      "           AdaBoost    1.0000     1.0000  1.0000    1.0000 1.0000 1.0000    0.3197\n",
      "\n",
      "================================================================================\n",
      "TEST SET RESULTS (GENERALIZATION)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "              Model  Accuracy  Precision  Recall  F1-Score  AUROC    MCC\n",
      "      Random Forest    0.9993     0.9997  0.9984    0.9990 1.0000 0.9979\n",
      "  Gradient Boosting    1.0000     1.0000  1.0000    1.0000 1.0000 1.0000\n",
      "Logistic Regression    0.8249     0.6578  0.8548    0.7066 0.9490 0.6466\n",
      "                SVM    0.7653     0.5924  0.7531    0.6323 0.9193 0.5147\n",
      "                MLP    0.9338     0.8856  0.8252    0.8522 0.9831 0.8042\n",
      "                KNN    0.8102     0.5370  0.4408    0.4559 0.7528 0.3246\n",
      "      Decision Tree    1.0000     1.0000  1.0000    1.0000 1.0000 1.0000\n",
      "        Naive Bayes    0.8344     0.6813  0.7460    0.6363 0.9616 0.6204\n",
      "        Extra Trees    0.6630     0.5460  0.7185    0.5530 0.8754 0.4319\n",
      "           AdaBoost    1.0000     1.0000  1.0000    1.0000 1.0000 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PART 2: Display Results Tables\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDATION SET RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "val_metrics = results_df[['Model', 'Val_Accuracy', 'Val_Precision', 'Val_Recall', \n",
    "                           'Val_F1', 'Val_AUROC', 'Val_MCC', 'Training_Time']].copy()\n",
    "val_metrics.columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', \n",
    "                       'AUROC', 'MCC', 'Time (s)']\n",
    "\n",
    "print(\"\\n\")\n",
    "print(val_metrics.to_string(index=False, float_format=lambda x: f'{x:.4f}'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST SET RESULTS (GENERALIZATION)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_metrics = results_df[['Model', 'Test_Accuracy', 'Test_Precision', 'Test_Recall', \n",
    "                            'Test_F1', 'Test_AUROC', 'Test_MCC']].copy()\n",
    "test_metrics.columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUROC', 'MCC']\n",
    "\n",
    "print(\"\\n\")\n",
    "print(test_metrics.to_string(index=False, float_format=lambda x: f'{x:.4f}'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8360dcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BEST MODELS BY METRIC\n",
      "================================================================================\n",
      "\n",
      "üèÜ Best Models (Test Set Performance):\n",
      "   Accuracy    : Gradient Boosting    (1.0000)\n",
      "   F1-Score    : Gradient Boosting    (1.0000)\n",
      "   AUROC       : Random Forest        (1.0000)\n",
      "   MCC         : Gradient Boosting    (1.0000)\n",
      "   Precision   : Gradient Boosting    (1.0000)\n",
      "   Recall      : Gradient Boosting    (1.0000)\n",
      "\n",
      "üéØ OVERALL BEST MODEL: Gradient Boosting\n",
      "   Test Accuracy:  1.0000 (100.00%)\n",
      "   Test F1-Score:  1.0000\n",
      "   Test AUROC:     1.0000\n",
      "   Test MCC:       1.0000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PART 3: Identify Best Models (CORRECTED)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST MODELS BY METRIC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_models = {\n",
    "    'Accuracy': results_df.loc[results_df['Test_Accuracy'].idxmax(), 'Model'],\n",
    "    'F1-Score': results_df.loc[results_df['Test_F1'].idxmax(), 'Model'],\n",
    "    'AUROC': results_df.loc[results_df['Test_AUROC'].idxmax(), 'Model'],\n",
    "    'MCC': results_df.loc[results_df['Test_MCC'].idxmax(), 'Model'],\n",
    "    'Precision': results_df.loc[results_df['Test_Precision'].idxmax(), 'Model'],\n",
    "    'Recall': results_df.loc[results_df['Test_Recall'].idxmax(), 'Model']\n",
    "}\n",
    "\n",
    "# Mapping between display names and column names\n",
    "metric_columns = {\n",
    "    'Accuracy': 'Test_Accuracy',\n",
    "    'F1-Score': 'Test_F1',\n",
    "    'AUROC': 'Test_AUROC',\n",
    "    'MCC': 'Test_MCC',\n",
    "    'Precision': 'Test_Precision',\n",
    "    'Recall': 'Test_Recall'\n",
    "}\n",
    "\n",
    "print(\"\\nüèÜ Best Models (Test Set Performance):\")\n",
    "for metric, model in best_models.items():\n",
    "    col_name = metric_columns[metric]\n",
    "    value = results_df[results_df['Model'] == model][col_name].values[0]\n",
    "    print(f\"   {metric:12s}: {model:20s} ({value:.4f})\")\n",
    "\n",
    "# Overall best model (based on F1-Score)\n",
    "best_model_name = results_df.loc[results_df['Test_F1'].idxmax(), 'Model']\n",
    "best_f1 = results_df['Test_F1'].max()\n",
    "best_auroc = results_df.loc[results_df['Model'] == best_model_name, 'Test_AUROC'].values[0]\n",
    "best_acc = results_df.loc[results_df['Model'] == best_model_name, 'Test_Accuracy'].values[0]\n",
    "best_mcc = results_df.loc[results_df['Model'] == best_model_name, 'Test_MCC'].values[0]\n",
    "\n",
    "print(f\"\\nüéØ OVERALL BEST MODEL: {best_model_name}\")\n",
    "print(f\"   Test Accuracy:  {best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
    "print(f\"   Test F1-Score:  {best_f1:.4f}\")\n",
    "print(f\"   Test AUROC:     {best_auroc:.4f}\")\n",
    "print(f\"   Test MCC:       {best_mcc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f2a7e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERALIZATION ANALYSIS (Val vs Test)\n",
      "================================================================================\n",
      "\n",
      "üìâ Performance Drop (Validation ‚Üí Test):\n",
      "\n",
      "\n",
      "              Model  Val F1  Test F1  F1 Drop  Val Acc  Test Acc  Acc Drop\n",
      "      Random Forest  1.0000   0.9990   0.0010   1.0000    0.9993    0.0007\n",
      "  Gradient Boosting  1.0000   1.0000   0.0000   1.0000    1.0000    0.0000\n",
      "Logistic Regression  0.7177   0.7066   0.0111   0.8263    0.8249    0.0015\n",
      "                SVM  0.6520   0.6323   0.0196   0.7682    0.7653    0.0029\n",
      "                MLP  0.8727   0.8522   0.0205   0.9455    0.9338    0.0118\n",
      "                KNN  0.4847   0.4559   0.0288   0.8263    0.8102    0.0162\n",
      "      Decision Tree  1.0000   1.0000   0.0000   1.0000    1.0000    0.0000\n",
      "        Naive Bayes  0.6568   0.6363   0.0205   0.8536    0.8344    0.0191\n",
      "        Extra Trees  0.5619   0.5530   0.0089   0.6652    0.6630    0.0022\n",
      "           AdaBoost  1.0000   1.0000   0.0000   1.0000    1.0000    0.0000\n",
      "\n",
      "üéØ Most Stable Model (best generalization): Gradient Boosting\n",
      "\n",
      "üíæ Results saved: ../data/model_evaluation_results.csv\n",
      "\n",
      "================================================================================\n",
      "‚úÖ EVALUATION COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PART 4: Generalization Analysis\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERALIZATION ANALYSIS (Val vs Test)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_df['F1_Diff'] = results_df['Val_F1'] - results_df['Test_F1']\n",
    "results_df['Acc_Diff'] = results_df['Val_Accuracy'] - results_df['Test_Accuracy']\n",
    "\n",
    "print(\"\\nüìâ Performance Drop (Validation ‚Üí Test):\")\n",
    "gen_analysis = results_df[['Model', 'Val_F1', 'Test_F1', 'F1_Diff', \n",
    "                            'Val_Accuracy', 'Test_Accuracy', 'Acc_Diff']].copy()\n",
    "gen_analysis.columns = ['Model', 'Val F1', 'Test F1', 'F1 Drop', \n",
    "                        'Val Acc', 'Test Acc', 'Acc Drop']\n",
    "print(\"\\n\")\n",
    "print(gen_analysis.to_string(index=False, float_format=lambda x: f'{x:.4f}'))\n",
    "\n",
    "# Find most stable model (smallest drop)\n",
    "most_stable = results_df.loc[results_df['F1_Diff'].abs().idxmin(), 'Model']\n",
    "print(f\"\\nüéØ Most Stable Model (best generalization): {most_stable}\")\n",
    "\n",
    "# ============================================================\n",
    "# PART 5: Save Results\n",
    "# ============================================================\n",
    "results_df.to_csv('../data/model_evaluation_results.csv', index=False)\n",
    "print(f\"\\nüíæ Results saved: ../data/model_evaluation_results.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ EVALUATION COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e036571c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
